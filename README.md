# AI-Powered Gesture, Expression & Voice Tool

This project is built to help **mute individuals** communicate using hand gestures and facial expressions, translating them into spoken words in real-time.

## âœ¨ Features
- ğŸ” Real-time **hand gesture recognition** (100+ patterns)
- ğŸ˜„ **Facial expression detection** (Happy, Sad, Angry, etc.)
- ğŸ—£ **Text-to-speech** in Hindi & English
- ğŸ™ **Voice command control** ("pause", "resume", "exit")
- ğŸ§ **User detection** using OpenCV (face presence)

## ğŸ–¥ How to Run
```bash
pip install -r requirements.txt
python AI-Gesture-OpenCV-Identity-Tool.py
AI-Gesture-Tool/
â”œâ”€â”€ AI-Gesture-OpenCV-Identity-Tool.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ gesture_log.csv        # (generated after first run)
â””â”€â”€ images/                # (optional: add screenshots or demos here)
ğŸ”§ Technologies Used
Python

OpenCV

MediaPipe

gTTS (Text to Speech)

Pygame

SpeechRecognition

ğŸ“¸ Demo
Add a demo GIF or screenshots in the images/ folder.

ğŸ“Œ Use Cases
Helping mute individuals express needs

Smart gesture-based AI interfaces

Educational tools for sign language

ğŸ¤ Contribution
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.
